
---
![Netflix Data Wrangling](/assets/images/Data%20wrangling.jpeg)
Data wrangling â€” also known as data cleaning â€” is one of the most crucial steps in any data science project. It's where raw, inconsistent, and messy data gets transformed into a format that's clean, organized, and ready for analysis. In this project, I worked on wrangling the [Netflix Movies and TV Shows dataset from Kaggle](https://www.kaggle.com/datasets/shivamb/netflix-shows).

## ğŸ§¹ The Dataset

The dataset contains information about Netflix titles, including attributes like:
- Title
- Director
- Cast
- Country
- Date added
- Release year
- Rating
- Duration
- Type
- Category

But like many real-world datasets, it wasnâ€™t clean.

## ğŸ› ï¸ Tools Used
- **Python**
- **Pandas**
- **Jupyter Notebook**

## ğŸ” Problems I Encountered

During initial inspection (`df.info()` and `df.isnull().sum()`), I noticed:
- **Missing values** in `director`, `cast`, `country`, `date_added`
- Inconsistent date formats
- Duplicates
- Mixed values in the `duration` column (e.g., â€œ1 Seasonâ€ vs â€œ90 minâ€)
- Typos and inconsistent capitalization in categorical data

## ğŸ§½ Cleaning Process

1. **Removed Duplicates**

```python
df.drop_duplicates(inplace=True)
Absolutely, Printon! Here's a well-structured blog post on **Data Wrangling**, based on the Netflix dataset assignment you worked on. This version is markdown-ready for your `_posts/` folder and includes placeholder spots for images if you want to add snapshots later.

---

### ğŸ“„ File Name (save in `_posts/`):

`2025-06-11-data-wrangling-netflix.md`

---

### âœ… Full Blog Markdown Code:

````markdown
---
title: "Cleaning the Mess: Data Wrangling with the Netflix Dataset"
date: 2025-06-11
layout: single
categories: [projects, data-science]
author_profile: true
read_time: true
---

Data wrangling â€” also known as data cleaning â€” is one of the most crucial steps in any data science project. It's where raw, inconsistent, and messy data gets transformed into a format that's clean, organized, and ready for analysis. In this project, I worked on wrangling the [Netflix Movies and TV Shows dataset from Kaggle](https://www.kaggle.com/datasets/shivamb/netflix-shows).

## ğŸ§¹ The Dataset

The dataset contains information about Netflix titles, including attributes like:
- Title
- Director
- Cast
- Country
- Date added
- Release year
- Rating
- Duration
- Type
- Category

But like many real-world datasets, it wasnâ€™t clean.

## ğŸ› ï¸ Tools Used
- **Python**
- **Pandas**
- **Jupyter Notebook**

## ğŸ” Problems I Encountered

During initial inspection (`df.info()` and `df.isnull().sum()`), I noticed:
- **Missing values** in `director`, `cast`, `country`, `date_added`
- Inconsistent date formats
- Duplicates
- Mixed values in the `duration` column (e.g., â€œ1 Seasonâ€ vs â€œ90 minâ€)
- Typos and inconsistent capitalization in categorical data

## ğŸ§½ Cleaning Process

1. **Removed Duplicates**

```python
df.drop_duplicates(inplace=True)
````

2. **Handled Missing Values**

For critical fields like `title` or `type`, I dropped rows. For others like `director`, I used `"Unknown"`:

```python
df['director'].fillna('Unknown', inplace=True)
```

3. **Date Standardization**

The `date_added` column had mixed formats. I converted it to datetime:

```python
df['date_added'] = pd.to_datetime(df['date_added'], errors='coerce')
```

4. **Standardized Text Data**

```python
df['rating'] = df['rating'].str.upper().str.strip()
df['country'] = df['country'].str.title().str.strip()
```

5. **Separated Duration**

I split the `duration` column into numeric and unit components:

```python
df[['duration_int', 'duration_type']] = df['duration'].str.extract('(\d+)\s+(\w+)')
df['duration_int'] = df['duration_int'].astype(float)
```

## ğŸ§¾ Before and After Cleaning

Before cleaning:

```plaintext
title       director    duration    rating     country
--------    ---------   --------    -------    --------
Movie A     NaN         1 Season    TV-14      United States
Movie A     NaN         1 Season    TV-14      United States
```

After cleaning:

```plaintext
title       director    duration_int    duration_type    rating     country
--------    ---------   -------------   --------------   -------    --------
Movie A     Unknown     1.0             Season           TV-14      United States
```

## âœ… Final Result

* Clean, deduplicated, and standardized dataset
* Separated duration and normalized text fields
* Handled all NaNs and removed irrelevant rows

## ğŸ§  Key Takeaways

* Always inspect your data before jumping to analysis.
* Missing data doesnâ€™t always need to be dropped â€” sometimes it can be labeled, filled, or transformed.
* Clean data is **the backbone** of accurate insights.

## ğŸ“Š What's Next?

Now that the data is clean, Iâ€™m planning to:

* Visualize content trends by year and country
* Compare movie vs. TV show growth over time
* Build a recommendation system using genres and user ratings

Stay tuned for the next post.
